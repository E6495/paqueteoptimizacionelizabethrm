<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Método del Gradiente Conjugado &#8212; Algoritmos_optimizacioneli 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../_static/documentation_options.js?v=2709fde1"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Método de Newton (Gradiente)" href="newton.html" />
    <link rel="prev" title="Método del Cauchy" href="cauchy.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="metodo-del-gradiente-conjugado">
<span id="gradienteconjugado"></span><h1>Método del Gradiente Conjugado<a class="headerlink" href="#metodo-del-gradiente-conjugado" title="Link to this heading">¶</a></h1>
<p>Esta sección describe la implementación del método de gradiente conjugado para la optimización.</p>
<section id="implementacion-del-metodo-de-gradiente-conjugado">
<h2>Implementación del Método de Gradiente Conjugado<a class="headerlink" href="#implementacion-del-metodo-de-gradiente-conjugado" title="Link to this heading">¶</a></h2>
<p>La función <cite>gradiente conjugado</cite> implementa el método de gradiente conjugado para la optimización de funciones escalares. Admite varios métodos de búsqueda unidireccional para encontrar un tamaño de paso (<cite>alpha</cite>) adecuado durante cada iteración:</p>
<ul class="simple">
<li><p><strong>Búsqueda Fibonacci</strong>: Utiliza el algoritmo de búsqueda Fibonacci para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Newton-Raphson</strong>: Utiliza el método de Newton-Raphson para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Búsqueda de la Sección Dorada</strong>: Aplica la búsqueda de la sección dorada para determinar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Intervalo de Mitad</strong>: Implementa el método de intervalo de mitad para <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Fase de Limitación</strong>: Utiliza el método de fase de limitación para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Búsqueda Exhaustiva</strong>: Aplica la búsqueda exhaustiva para determinar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Bisección</strong>: Implementa el método de bisección para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Secante</strong>: Utiliza el método de la secante para determinar <cite>alpha</cite>.</p></li>
</ul>
<p>Cada uno de estos métodos ofrece diferentes enfoques para determinar el tamaño de paso <cite>alpha</cite> basado en el comportamiento de la función.</p>
</section>
<section id="funcion-de-gradiente">
<h2>Función de Gradiente<a class="headerlink" href="#funcion-de-gradiente" title="Link to this heading">¶</a></h2>
<p>La función de gradiente calcula el gradiente de una función en un punto dado utilizando aproximaciones numéricas de las derivadas parciales.</p>
<section id="parametros">
<h3>Parámetros<a class="headerlink" href="#parametros" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f</span></code> (callable): Función cuyo gradiente se desea calcular.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code> (array-like): Punto en el cual se evalúa el gradiente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">deltaX</span></code> (float, optional): Paso para la aproximación numérica de las derivadas parciales. Por defecto es 0.001.</p></li>
</ul>
</section>
<section id="retorna">
<h3>Retorna<a class="headerlink" href="#retorna" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">list</span></code>: Gradiente de <code class="docutils literal notranslate"><span class="pre">f</span></code> en <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p></li>
</ul>
</section>
<section id="ejemplo-de-uso">
<h3>Ejemplo de Uso<a class="headerlink" href="#ejemplo-de-uso" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">optimizacioneli.multivariable</span> <span class="kn">import</span> <span class="n">gradiente</span>

<span class="c1"># Definir una función de prueba</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Punto en el cual evaluar el gradiente</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>

<span class="c1"># Calcular el gradiente</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">gradiente</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gradiente en </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gradient</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="metodo-de-gradiente-conjugado">
<h2>Método de Gradiente Conjugado<a class="headerlink" href="#metodo-de-gradiente-conjugado" title="Link to this heading">¶</a></h2>
<p>El método de gradiente conjugado es un método iterativo para la minimización de funciones que utiliza la dirección conjugada de búsqueda para actualizar iterativamente el punto de evaluación.</p>
<section id="id1">
<h3>Parámetros<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f</span></code> (callable): Función objetivo a minimizar.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x0</span></code> (array-like): Punto inicial de búsqueda.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon1</span></code> (float): Tolerancia para el paso de línea.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon2</span></code> (float): Tolerancia para la norma del cambio relativo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon3</span></code> (float): Tolerancia para la norma del gradiente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metodo</span></code> (str): Método para la búsqueda de paso de línea (‘biseccion’, ‘interval’, ‘bounding’, ‘secante’, ‘exhaustiva’, ‘dorado’, ‘fibonacci’, ‘newton’).</p></li>
</ul>
</section>
<section id="id2">
<h3>Retorna<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">array-like</span></code>: Punto óptimo encontrado que minimiza la función <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p></li>
</ul>
</section>
<section id="id3">
<h3>Ejemplo de Uso<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">optimizacioneli.multivariable</span> <span class="kn">import</span> <span class="n">conjugate_gradient</span>

<span class="c1"># Definir una función de prueba</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Punto inicial y parámetros</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">epsilon1</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epsilon2</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epsilon3</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">metodo</span> <span class="o">=</span> <span class="s1">&#39;biseccion&#39;</span>  <span class="c1"># Seleccionar método de búsqueda de paso</span>

<span class="c1"># Aplicar el método de gradiente conjugado</span>
<span class="n">optimal_point</span> <span class="o">=</span> <span class="n">conjugate_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">epsilon1</span><span class="p">,</span> <span class="n">epsilon2</span><span class="p">,</span> <span class="n">epsilon3</span><span class="p">,</span> <span class="n">metodo</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Punto óptimo encontrado:&quot;</span><span class="p">,</span> <span class="n">optimal_point</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Algoritmos_optimizacioneli</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../funciones/funcionesobjetivo.html">Funciones de Optimización</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/colina.html">Algoritmo de Colina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/hookejeeves.html">Método de Hooke-Jeeves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/neldermeadsimplex.html">Algoritmo de Mead (Nelder-Mead)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/randomwalk.html">Algoritmo Random Walk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/recocido.html">Método de Recocido Simulado</a></li>
<li class="toctree-l1"><a class="reference internal" href="cauchy.html">Método del Cauchy</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Método del Gradiente Conjugado</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#implementacion-del-metodo-de-gradiente-conjugado">Implementación del Método de Gradiente Conjugado</a></li>
<li class="toctree-l2"><a class="reference internal" href="#funcion-de-gradiente">Función de Gradiente</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metodo-de-gradiente-conjugado">Método de Gradiente Conjugado</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="newton.html">Método de Newton (Gradiente)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/biseccion.html">Método de Bisección para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/newton.html">Método de Newton-Raphson para Encontrar Raíces de Funciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/secante.html">Método de la Secante para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/bounding.html">Método de la Fase de Búsqueda para Encontrar Mínimos Locales</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/exhaustiva.html">Método de Búsqueda Exhaustiva para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/fibonacci.html">Método de Búsqueda de Fibonacci para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/golden.html">Método de Búsqueda Dorada para Encontrar un Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/intervalhalving.html">Método de Interval Halving Method para Encontrar un Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils/graficas.html">Gráficas 2D de Funciones con y sin Restricciones</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="cauchy.html" title="previous chapter">Método del Cauchy</a></li>
      <li>Next: <a href="newton.html" title="next chapter">Método de Newton (Gradiente)</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, ElizabethRM.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../../_sources/optimizacioneli/multivariable/metodosgradiente/gradienteconjugado.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>