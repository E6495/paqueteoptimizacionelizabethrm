<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Método del Cauchy &#8212; Algoritmos_optimizacioneli 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../_static/documentation_options.js?v=2709fde1"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Método del Gradiente Conjugado" href="gradienteconjugado.html" />
    <link rel="prev" title="Método de Recocido Simulado" href="../metodosdirectos/recocido.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="metodo-del-cauchy">
<span id="cauchy"></span><h1>Método del Cauchy<a class="headerlink" href="#metodo-del-cauchy" title="Link to this heading">¶</a></h1>
<p>Esta sección describe la implementación del método de Cauchy para la optimización.</p>
<section id="implementacion-del-metodo-de-cauchy">
<h2>Implementación del Método de Cauchy<a class="headerlink" href="#implementacion-del-metodo-de-cauchy" title="Link to this heading">¶</a></h2>
<p>La función <cite>Cauchy</cite> implementa el método de Cauchy para la optimización de funciones escalares. Admite varios métodos de búsqueda unidireccional para encontrar un tamaño de paso (<cite>alpha</cite>) adecuado durante cada iteración:</p>
<ul class="simple">
<li><p><strong>Búsqueda Fibonacci</strong>: Utiliza el algoritmo de búsqueda Fibonacci para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Cauchy-Raphson</strong>: Utiliza el método de Cauchy-Raphson para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Búsqueda de la Sección Dorada</strong>: Aplica la búsqueda de la sección dorada para determinar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Intervalo de Mitad</strong>: Implementa el método de intervalo de mitad para <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Fase de Limitación</strong>: Utiliza el método de fase de limitación para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Búsqueda Exhaustiva</strong>: Aplica la búsqueda exhaustiva para determinar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Bisección</strong>: Implementa el método de bisección para encontrar <cite>alpha</cite>.</p></li>
<li><p><strong>Método de Secante</strong>: Utiliza el método de la secante para determinar <cite>alpha</cite>.</p></li>
</ul>
<p>Cada uno de estos métodos ofrece diferentes enfoques para determinar el tamaño de paso <cite>alpha</cite> basado en el comportamiento de la función.</p>
</section>
<section id="funcion-de-gradiente">
<h2>Función de Gradiente<a class="headerlink" href="#funcion-de-gradiente" title="Link to this heading">¶</a></h2>
<p>La función de gradiente calcula el gradiente de una función en un punto dado utilizando aproximaciones numéricas de las derivadas parciales.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f</span></code> (callable): Función cuyo gradiente se desea calcular.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code> (array-like): Punto en el cual se evalúa el gradiente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">deltaX</span></code> (float, optional): Paso para la aproximación numérica de las derivadas parciales. Por defecto es 0.001.</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">list</span></code>: Gradiente de <code class="docutils literal notranslate"><span class="pre">f</span></code> en <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">optimizacioneli.multivariable</span> <span class="kn">import</span> <span class="n">gradiente</span>

<span class="c1"># Definir una función de prueba</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Punto en el cual evaluar el gradiente</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>

<span class="c1"># Calcular el gradiente</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">gradiente</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gradiente en </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gradient</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="metodo-de-cauchy">
<span id="optimizacioneli-multivariable-conjugate-gradient"></span><h2>Método de Cauchy<a class="headerlink" href="#metodo-de-cauchy" title="Link to this heading">¶</a></h2>
<p>El método de Cauchy trabaja bien cuando el punto inicial se encuentra lejos del óptimo.
Cuando el punto actual está muy cercano el cambio en el gradiente es pequeño. Esto hace que la convergencia se lenta, para acelerarla se puede usar las derivadas de segundo orden.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">funcion</span></code> (callable): Función objetivo a minimizar.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x0</span></code> (array-like): Punto inicial de búsqueda.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon1</span></code> (float): Tolerancia para la norma del gradiente que determina la convergencia.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon2</span></code> (float): Tolerancia para la diferencia relativa entre dos iteraciones consecutivas.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">M</span></code> (int): Número máximo de iteraciones permitidas.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metodo</span></code> (str): Método para la búsqueda de paso de línea (‘biseccion’, ‘interval’, ‘bounding’, ‘secante’, ‘exhaustiva’, ‘dorado’, ‘fibonacci’, ‘newton’).</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">array-like</span></code>: Punto óptimo encontrado que minimiza la función <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">optimizacioneli.multivariable</span> <span class="kn">import</span> <span class="n">cauchy</span>

<span class="c1"># Definir una función de prueba</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Punto inicial y parámetros</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">epsilon1</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epsilon2</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">metodo</span> <span class="o">=</span> <span class="s1">&#39;secante&#39;</span>  <span class="c1"># Seleccionar método de búsqueda de paso</span>

<span class="c1"># Aplicar el método de Cauchy</span>
<span class="n">optimal_point</span> <span class="o">=</span> <span class="n">cauchy</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">epsilon1</span><span class="p">,</span> <span class="n">epsilon2</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">metodo</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Punto óptimo encontrado:&quot;</span><span class="p">,</span> <span class="n">optimal_point</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Algoritmos_optimizacioneli</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../funciones/funcionesobjetivo.html">Funciones de Optimización</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/colina.html">Algoritmo de Colina</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/hookejeeves.html">Método de Hooke-Jeeves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/neldermeadsimplex.html">Algoritmo de Mead (Nelder-Mead)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/randomwalk.html">Algoritmo Random Walk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metodosdirectos/recocido.html">Método de Recocido Simulado</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Método del Cauchy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#implementacion-del-metodo-de-cauchy">Implementación del Método de Cauchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#funcion-de-gradiente">Función de Gradiente</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metodo-de-cauchy">Método de Cauchy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gradienteconjugado.html">Método del Gradiente Conjugado</a></li>
<li class="toctree-l1"><a class="reference internal" href="newton.html">Método de Newton (Gradiente)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/biseccion.html">Método de Bisección para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/newton.html">Método de Newton-Raphson para Encontrar Raíces de Funciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodosbasadosenladerivada/secante.html">Método de la Secante para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/bounding.html">Método de la Fase de Búsqueda para Encontrar Mínimos Locales</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/exhaustiva.html">Método de Búsqueda Exhaustiva para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/fibonacci.html">Método de Búsqueda de Fibonacci para Encontrar Intervalo de Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/golden.html">Método de Búsqueda Dorada para Encontrar un Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../univariable/metodoseliminacionderegiones/intervalhalving.html">Método de Interval Halving Method para Encontrar un Mínimo Local</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils/graficas.html">Gráficas 2D de Funciones con y sin Restricciones</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../metodosdirectos/recocido.html" title="previous chapter">Método de Recocido Simulado</a></li>
      <li>Next: <a href="gradienteconjugado.html" title="next chapter">Método del Gradiente Conjugado</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, ElizabethRM.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../../_sources/optimizacioneli/multivariable/metodosgradiente/cauchy.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>